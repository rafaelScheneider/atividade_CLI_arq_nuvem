name: Data Pipeline CI/CD

on:
  push:
    branches: [ "main" ]
    paths:
      - 'data/*.csv' # dispara apenas quando CSVs em /data mudarem
  workflow_dispatch: # permite rodar manualmente

jobs:
  data-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configurar credenciais AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
            aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
            aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload original para RAW
        run: |
          aws s3 cp ./data/ s3://${{ secrets.S3_BUCKET_NAME }}/raw/ \
          --recursive --exclude "*" --include "*.csv"

      - name: Instalar dependÃªncias Python
        run: |
          python -m pip install --upgrade pip
          pip install pandas

      - name: Transformar dados (Trusted/Client)
        run: |
          python scripts/transform.py ./data/ ./output/

      - name: Upload TRUSTED
        run: |
          aws s3 cp ./output/ s3://${{ secrets.S3_BUCKET_NAME }}/trusted/ \
          --recursive --exclude "*" --include "trusted_*.csv"

      - name: Upload CLIENT
        run: |
          aws s3 cp ./output/ s3://${{ secrets.S3_BUCKET_NAME }}/client/ \
          --recursive --exclude "*" --include "client_*.csv"
